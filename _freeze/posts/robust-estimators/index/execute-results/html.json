{
  "hash": "a4e6eacf2c0ae422cf7c4c8c61ab491e",
  "result": {
    "markdown": "---\ntitle: Statistical simulation of robust estimators with tidyverse tools\ndescription:  Functions from the `tidyverse` provide a powerful way to do statistical simulations. We demonstrate this approach by evaluating the properties of the mean and median as estimators of center for two distributions.\"\nauthor: Max Rohde\ndate: 01/13/2021\nimage: preview.png\ncode-fold: show\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(tidyverse)\n\n# Formatting of HTML tables\nlibrary(kableExtra)\n\n# Set global ggplot theme\ntheme_set(cowplot::theme_cowplot(font_size=12,\n                                 font_family = \"Source Sans Pro\"))\n\nset.seed(7)\n```\n:::\n\n\nThe sample mean and sample median are commonly used estimators for the center of distribution. There is no such thing as a \"best estimator\" in all circumstances. However, estimators can outperform other estimators in terms of desirable properties (e.g., unbiasedness, low variance, consistency) given a particular circumstance. We can use simulation and mathematical theory to evaluate the performance of estimators. Here we focus on using simulation, with the help of tools from the `tidyverse`.\n\n## Scenario 1\n\nWe begin with a simple example. The true data generating process is\n$$ X_1, X_2, \\ldots X_n \\stackrel{iid}{\\sim} N(3,1) $$\n\nHow will the mean and median perform as estimators of the true mean, $\\mu = 3$? Let's use simulation to find out.\n\nWe will use a `tibble` to store all of our simulation results. First, let's decide what sample sizes to simulate, and how many trials to run. The more trials we run, the more accurate our simulation results will be -- the cost being increased time to run the simulations and memory to store the results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsize <- c(5,10,20,50,100,200)\ntrial <- 1:1e5\n```\n:::\n\n\nNow we use `crossing()` to generate a `tibble` that contains every combination of the vectors `size` and `trial`. So for every sample size, we are repeating it 100,000 times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- crossing(trial, size)\n```\n:::\n\n\nWe can look at the first 15 rows:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   trial  size\n   <int> <dbl>\n 1     1     5\n 2     1    10\n 3     1    20\n 4     1    50\n 5     1   100\n 6     1   200\n 7     2     5\n 8     2    10\n 9     2    20\n10     2    50\n```\n:::\n:::\n\n\nNow for each row, we want to add to our data frame a sample of data with the sample size given by that row. We will use `purrr::map()` to do this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$data <- map(df$size, ~rnorm(n=.x, mean = 3, sd=1))\n```\n:::\n\n\nThe first argument to `map` is the vector to iterate over, and the second argument is the function to apply. We use `.x` as a dummy variable to refer to the value in the current iteration. We can interpret this as saying, for each of the $6 \\times 10^5$ `size` records in our data, generate `size` observations from a N(3,1) distribution.\n\nThe new column, `data`, is a list of lists, where each list contains a sample of data. Let's see what this looks like.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 3\n   trial  size data       \n   <int> <dbl> <list>     \n 1     1     5 <dbl [5]>  \n 2     1    10 <dbl [10]> \n 3     1    20 <dbl [20]> \n 4     1    50 <dbl [50]> \n 5     1   100 <dbl [100]>\n 6     1   200 <dbl [200]>\n 7     2     5 <dbl [5]>  \n 8     2    10 <dbl [10]> \n 9     2    20 <dbl [20]> \n10     2    50 <dbl [50]> \n```\n:::\n:::\n\n\nNow that we have our data, we can compute the mean and median for each sample.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$mean <- map_dbl(df$data, ~mean(.x))\ndf$median <- map_dbl(df$data, ~median(.x))\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 5\n   trial  size data         mean median\n   <int> <dbl> <list>      <dbl>  <dbl>\n 1     1     5 <dbl [5]>    2.80   2.31\n 2     1    10 <dbl [10]>   3.96   3.55\n 3     1    20 <dbl [20]>   3.14   3.15\n 4     1    50 <dbl [50]>   3.07   3.09\n 5     1   100 <dbl [100]>  3.16   3.32\n 6     1   200 <dbl [200]>  2.96   2.95\n 7     2     5 <dbl [5]>    2.52   2.78\n 8     2    10 <dbl [10]>   2.83   2.80\n 9     2    20 <dbl [20]>   3.08   3.14\n10     2    50 <dbl [50]>   2.93   2.86\n```\n:::\n:::\n\n\nThe mean and median of each sample are now in separate columns. However, to get the data into tidy format, also known as long format, we want them in separate rows. Having the data in tidy format allows us to use `ggplot2` and other tidyverse functions more effectively. We use `pivot_longer` to do this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- pivot_longer(df,\n                   cols=mean:median,\n                   names_to=\"Estimator\",\n                   values_to=\"Estimate\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 5\n   trial  size data        Estimator Estimate\n   <int> <dbl> <list>      <chr>        <dbl>\n 1     1     5 <dbl [5]>   mean          2.80\n 2     1     5 <dbl [5]>   median        2.31\n 3     1    10 <dbl [10]>  mean          3.96\n 4     1    10 <dbl [10]>  median        3.55\n 5     1    20 <dbl [20]>  mean          3.14\n 6     1    20 <dbl [20]>  median        3.15\n 7     1    50 <dbl [50]>  mean          3.07\n 8     1    50 <dbl [50]>  median        3.09\n 9     1   100 <dbl [100]> mean          3.16\n10     1   100 <dbl [100]> median        3.32\n```\n:::\n:::\n\n\nNow we are finally ready to analyze the results of our simulation. First, let's compute the bias and variance of our estimators for each sample size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_df <-\ndf %>%\n  group_by(size, Estimator) %>%\n  summarize(Bias = (mean(Estimate) - 3),\n            Variance = var(Estimate)) %>%\n  pivot_longer(Bias:Variance)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 24 × 4\n# Groups:   size [6]\n    size Estimator name          value\n   <dbl> <chr>     <chr>         <dbl>\n 1     5 mean      Bias      0.0000212\n 2     5 mean      Variance  0.199    \n 3     5 median    Bias      0.00141  \n 4     5 median    Variance  0.286    \n 5    10 mean      Bias     -0.000959 \n 6    10 mean      Variance  0.100    \n 7    10 median    Bias     -0.000314 \n 8    10 median    Variance  0.138    \n 9    20 mean      Bias      0.000634 \n10    20 mean      Variance  0.0502   \n# ℹ 14 more rows\n```\n:::\n:::\n\n\nPlotting the bias and variance as a function of sample size, we see that both the mean and median are unbiased estimators of the center of the true distribution, but the median has higher variance. Therefore, we would prefer the mean under these assumptions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_df %>%\n  ggplot() +\n  aes(x=size, y=value, color=Estimator) +\n  geom_line(alpha=0.6) +\n  geom_point(alpha=0.6) +\n  facet_wrap(~name) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = c(0.8,0.8)) +\n  labs(\n    x = \"Sample Size\",\n    y = \"Estimated Value\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=768}\n:::\n:::\n\n\nPlotting the sampling distribution for each of the estimators shows that the median indeed has higher variance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlabel_names <- as_labeller(c(`5` = \"Sample Size: 5\",\n                             `10` = \"Sample Size: 10\",\n                             `20` = \"Sample Size: 20\",\n                             `50` = \"Sample Size: 50\",\n                             `100` = \"Sample Size: 100\",\n                             `200` = \"Sample Size: 200\")) \n\ndf %>%\n  ggplot() +\n  aes(x=Estimate, color=Estimator, fill=Estimator) +\n  geom_density(alpha=0.3, size=0.8) +\n  facet_wrap(~size, labeller=label_names) +\n  geom_vline(aes(xintercept = 3), linetype=2, alpha=0.3) +\n  coord_cartesian(xlim=c(1,5), ylim=c(0,6)) +\n  scale_fill_brewer(palette = \"Set1\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = c(0.88,0.88)) +\n  labs(\n    title = \"Normal(3,1) Distribution\",\n    subtitle = \"Performance of mean and median\",\n    x=\"Estimate\",\n    y=\"PDF\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=768}\n:::\n:::\n\n\n\n## Scenario 2\n\nNow let's take a look at a distribution with heavier tails than the normal. An example is a mixture of normal two distributions.\n\nThe data-generating process is this:\n\n- With probability 0.9, draw from the $N(3, 1)$ distribution.\n- Otherwise, (with probability 0.1), draw from the $N(3, 10)$ distribution.\n\nWe can write a function to draw from this distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generates 1 draw from the specifies mixture normal distribution\nmixed_normal <- function(){\n  x <- runif(1)\n  if (x>0.1) {\n    return(rnorm(n=1, mean = 3, sd=1))\n  }\n  else{\n    return(rnorm(n=1, mean = 3, sd=10))\n  }\n}\n\n# generates n draws from the specifies mixture normal distribution\nrmixed_norm  <- function(n){\n  map_dbl(1:n, ~mixed_normal())\n}\n```\n:::\n\n\nPlotting the normal distribution and the mixture distribution on top of each other, we see that they are very similar, but the mixture distribution has heavier tails (i.e., more of the probability mass is in the tails compared to the normal distribution).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(normal = rnorm(1e5, mean=3),\n       mixture = rmixed_norm(1e5)) %>%\n  pivot_longer(cols=normal:mixture, names_to=\"Distribution\", values_to=\"value\") %>%\n  ggplot() +\n  aes(x=value, color=Distribution) +\n  geom_density(alpha=0.7)+\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = c(0.88,0.90)) +\n  labs(\n    title = \"Mixture Normal vs Normal Distribution\",\n    subtitle = \"\",\n    x= \"X\",\n    y= \"PDF\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=768}\n:::\n:::\n\n\nNow let's compare the performance of the mean and median on the mixture distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsize <- c(5,10,20,50,100,200)\ntrial <- 1:1e5\n\ndf <- crossing(trial, size)\n\ndf$data <- map(df$size, ~rmixed_norm(n=.x))\n\ndf$mean <- map_dbl(df$data, ~mean(.x))\ndf$median <- map_dbl(df$data, ~median(.x))\n\ndf <- pivot_longer(df, cols=mean:median, names_to=\"Estimator\", values_to=\"Estimate\")\n\ndf %>%\n  group_by(size, Estimator) %>%\n  summarize(Bias = (mean(Estimate) - 3),\n            Variance = var(Estimate)) %>%\n  pivot_longer(Bias:Variance) -> summary_df\n\n\nsummary_df %>%\n  ggplot() +\n  aes(x=size, y=value, color=Estimator) +\n  geom_line(alpha=0.6) +\n  geom_point(alpha=0.6) +\n  facet_wrap(~name) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = c(0.8,0.8)) +\n  labs(\n    x = \"Sample Size\",\n    y = \"Estimated Value\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=768}\n:::\n\n```{.r .cell-code}\nlabel_names <- as_labeller(c(`5` = \"Sample Size: 5\",\n                             `10` = \"Sample Size: 10\",\n                             `20` = \"Sample Size: 20\",\n                             `50` = \"Sample Size: 50\",\n                             `100` = \"Sample Size: 100\",\n                             `200` = \"Sample Size: 200\")) \n\ndf %>%\n  ggplot() +\n  aes(x=Estimate, color=Estimator, fill=Estimator) +\n  geom_density(alpha=0.3, size=0.8) +\n  facet_wrap(~size, labeller=label_names) +\n  geom_vline(aes(xintercept = 3), linetype=2, alpha=0.3) +\n  coord_cartesian(xlim=c(1,5), ylim=c(0,6)) +\n  scale_fill_brewer(palette = \"Set1\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = c(0.88,0.88)) +\n  labs(\n    title = \"Mixture Normal Distribution\",\n    subtitle = \"Performance of mean and median\",\n    x=\"Estimate\",\n    y=\"PDF\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-2.png){width=768}\n:::\n:::\n\n\nIt looks like the median greatly outperforms the mean! Both are unbiased, but the median has lower variance.\n\n## Take-away points\n\n- Simulation is a powerful tool in statistics. Here we showed how is can be used to compare the properties of estimators.\n- For distributions with heavy tails, the median may be a better estimator of center than the mean.\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}