{
  "hash": "cc3efe22dd4932fe1b745763e2f63f9a",
  "result": {
    "markdown": "---\ntitle: Code-breaking with Markov Chain Monte Carlo (MCMC)\ndescription: Using cryptography to demonstrate the power of MCMC techniques in computational statistics\nauthor: Max Rohde\ndate: 11/10/2022\nimage: preview.png\ncode-fold: false\n---\n\n\n\n\n## Overview\n\nIn this post we will show how a common method in computational statistics, Markov Chain Monte Carlo (implemented using the Metropolis algorithm), can be used to decode hidden messages encoded using a substitution cipher^[From Merriam-Webster, a cipher is defined as \"a method of transforming a text in order to conceal its meaning\"].\n\nTo cut to the chase, here's a video of the algorithm in action running on my laptop:\n\n![](demo.mp4){fig-width=100%}\n\nWe see that within a few hundred iterations of the algorithm, the true text is revealed. This post will explain the theory of how this works and will describe the computational details using R. Many of the details were inspired by an example given by Persi Diaconis in his paper \"The Markov Chain Monte Carlo Revolution\"^[<https://math.uchicago.edu/~shmuel/Network-course-readings/MCMCRev.pdf>].\n\n## The substitution cipher\n\nThe substitution cipher is one of the simplest cryptographic methods. It works by swapping each letter in the alphabet with another.\n\nOne simple type of substitution cipher is a shift cipher, where we shift the alphabet by a certain number of units. So a shift cipher with a shift of 3 would yield:\n\n```\nOriginal Alpabet:  abcdefghijklmnopqrstuvwxyz\nCipher Alphabet:   defghijklmnopqrstuvwxyzabc\n```\n\nWith this cipher, the word `hello` would map to:\n\n- `h -> k`\n- `e -> h`\n- `l -> o`\n- `l -> o`\n- `o -> r`\n\nresulting in the ciphertext `khoor`.\n\n:::{.callout-note collapse=\"false\"}\n## Terminology\n**Plaintext** refers to the text you input to the cipher (\"hello\") and **ciphertext** refers to the output of the cipher (\"khoor\").\n:::\n\nWe can do this in R using the built-in `chartr()` function, which encodes a given string from one alphabet to another.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchartr(\n  x = \"hello\",\n  old = \"abcdefghijklmnopqrstuvwxyz\",\n  new = \"defghijklmnopqrstuvwxyzabc\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"khoor\"\n```\n:::\n:::\n\n\nMore generally, we can create an arbitrary substitution cipher by permuting the letters of the alphabet.\n\n[`letters` is a built-in R object that contains the 26 letters of the English alphabet.]{.aside}\n\n[`paste(collapse = \"\")` is used to turn a vector of characters into a single string.]{.aside}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nletters |> paste(collapse = \"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"abcdefghijklmnopqrstuvwxyz\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsample(letters) |> paste(collapse = \"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"xasljwipdrvgfeuohbkmntzyqc\"\n```\n:::\n:::\n\n\nWe can use the above code to create three functions which\n\n1) Generate a random cipher\n2) Encode plaintext with a given cipher\n3) Decode ciphertext with a given cipher\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate a new cipher by permuting the letters of the alphabet\ngenerate_cipher <- function() sample(letters,\n                                     replace = FALSE)\n\n# Encode a text using a cipher\nencode_text <- function(text, cipher) {\n  chartr(\n    x = text,\n    old = paste(letters, collapse = \"\"),\n    new = paste(cipher, collapse = \"\")\n  )\n}\n\n# Decode a text given a cipher\ndecode_text <- function(ciphered_text, cipher) {\n  chartr(\n    x = ciphered_text,\n    old = paste(cipher, collapse = \"\"),\n    new = paste(letters, collapse = \"\")\n  )\n}\n```\n:::\n\n\nLet's test these functions to make sure they're working correctly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaintext <- \"to be or not to be that is the question whether tis nobler in the mind to suffer the slings and arrows of outrageous fortune or to take arms against a sea of troubles\"\n\n# Create and store the cipher\ntrue_cipher <- generate_cipher()\nprint(true_cipher)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"w\" \"r\" \"j\" \"n\" \"p\" \"t\" \"a\" \"q\" \"k\" \"y\" \"l\" \"h\" \"b\" \"z\" \"u\" \"s\" \"i\" \"o\" \"e\"\n[20] \"x\" \"f\" \"g\" \"v\" \"d\" \"m\" \"c\"\n```\n:::\n:::\n\n\nHere's what the ciphertext looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Encode the plaintext\nciphertext <- encode_text(plaintext, true_cipher)\nprint(ciphertext)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"xu rp uo zux xu rp xqwx ke xqp ifpexkuz vqpxqpo xke zurhpo kz xqp bkzn xu efttpo xqp ehkzae wzn woouve ut ufxowapufe tuoxfzp uo xu xwlp wobe wawkzex w epw ut xoufrhpe\"\n```\n:::\n:::\n\n\nAnd we see that decoding it with the true cipher recovers the plaintext:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Decode the ciphertext\ndecoded_text <- decode_text(ciphertext, true_cipher)\nprint(decoded_text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"to be or not to be that is the question whether tis nobler in the mind to suffer the slings and arrows of outrageous fortune or to take arms against a sea of troubles\"\n```\n:::\n:::\n\n\n## Overview of the Metropolis algorithm\n\n### Why not use brute force?\n\nSuppose we intercept the ciphertext above, but we didn't know the true cipher. How could we decode the hidden message?\n\nA brute force idea would be to try all possible ciphers until we find the correct one. How long would it take to try all possible ciphers? There are $26!$ ciphers to check because they are formed from permutations of the alphabet.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactorial(26)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.032915e+26\n```\n:::\n:::\n\n\nThat's a very big number! Just for argument sake, let's assume that we have access to the fastest supercomputer in the world^[<https://arstechnica.com/information-technology/2022/05/1-1-quintillion-operations-per-second-us-has-worlds-fastest-supercomputer/>]. It's reported that it can compute 1.1 quintillion operations ($1.1 \\times 10^{18}$) per second. Although checking a cipher would take more than a single operation, let's assume that we can check a cipher in a single operation (since we are seeing if this is even feasible).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactorial(26) / (1.1 * 10^18)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 366628601\n```\n:::\n:::\n\n\n$$\n(4.03 \\times 10^{26}) \\text{ ciphers} \\times \\left(\\frac{1 \\text{ second}}{1.1 \\times 10^{18} \\text{ciphers}}\\right) \\approx 366 \\text{ million seconds} \\approx 11.6 \\text{ years} \n$$\n\nSo even with the fastest computer in the world, and with some very generous assumptions about how many operations it takes to check a cipher, it would still take 11.6 years to test all of them. Let's learn a much faster way to solve this problem. We don't even need a supercomputer; a laptop will do just fine.\n\n### The Metropolis algorithm\n\nSo, how can we beat the brute force method? The idea is to use an algorithm that seeks out the likely ciphers, and ignores the ciphers that are unlikely to be correct. This is what the Metropolis algorithm does.\n\nThe Metropolis algorithm is a Markov Chain Monte Carlo algorithm, which means that it is used to generate Markov Chains that converge to a desirable stationary distribution^[For a review of Markov chains, see <https://setosa.io/ev/markov-chains/> and <https://youtu.be/i3AkTO9HLXo>]. Markov chains are defined on a state space, where the chain is traveling from state to state. In the framework of our problem, the states our Markov Chain is traveling between are the $26!$ possible ciphers. We want to the Markov chain to travel to the ciphers that are more \"likely to be correct\" and stay away from the ciphers that are \"unlikely to be correct\". While we will elaborate on this later, we can tentatively define \"likely to be correct\" ciphers as those that produce text that looks similar to English.\n\nLet $\\text{sim}(\\text{cipher})$ be a function that returns a score from 0 and 1 indicating how similar the text that a cipher produces is to English. With the $\\text{sim}(\\text{cipher})$ function defined, the Metropolis algorithm works like this. First, start with a randomly chosen cipher as the initial state. Then repeat the following steps until the code is cracked:\n\n1) Choose a new (but closely related) cipher by swapping two letters in the current cipher at random. This is called the **proposal cipher**.\n2) Compute the quantity $\\frac{\\text{sim}(\\text{proposal cipher})}{\\text{sim}(\\text{current cipher})}$. If the proposal cipher produces text more similar to English than the current cipher, this ratio will always be greater than 1. If the current cipher produces text more similar to English than the proposal cipher, this ratio will be between 0 and 1.\n3) If the ratio in the previous step is greater than 1, set the current cipher to the proposed cipher. This is called **accepting the proposal**.\n4) If the ratio is less than 1, accept the proposal with probability equal to $\\frac{\\text{sim}(\\text{proposal cipher})}{\\text{sim}(\\text{current cipher})}$ and reject it (i.e., stay at the current cipher) with probability $1 - \\frac{\\text{sim}(\\text{proposal cipher})}{\\text{sim}(\\text{current cipher})}$.\n\nIn other words, if the proposal cipher produces text more similar to English than the current cipher, we always accept it; and if the current cipher produces text more similar to English than the proposal cipher, we accept or reject it with probability given by the ratio of their scores. The worse a proposal performs, the less likely it will be accepted. The intuition behind this method is that it will travel towards ciphers that produce text more similar to English and ignore ciphers that don't.\n\n:::{.callout-note collapse=\"false\"}\n## The Metropolis algorithm and Bayesian statistics\nTechnically, the Metropolis algorithm is designed to travel to states in proportion to the probability of each state. So by running the Metropolis algorithm on the space of ciphers, we are approximately sampling from the probability distribution of ciphers given the ciphertext, a concept that will be very familiar to those who use Bayesian statistics. Indeed, the Metropolis algorithm is used to perform Bayesian statistics in a variety of settings where an analytical approach is not feasible.\n\nWe are using the Metropolis algorithm here for optimization rather than sampling, a nice side-effect of the property that when sampling according to each state's probability, high probability states are visited frequently.\n:::\n\nTo implement this algorithm, we need for formalize our notion of an \"English-similarity score\". This will be the topic of the next section.\n\n## Defining an \"English-similarity score\"\n\nWe need some way of measuring how similar to English an arbitrary text looks. Even a non-native speaker could likely tell that\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"xu rp uo zux xu rp xqwx ke xqp ifpexkuz vqpxqpo xke zurhpo kz xqp bkzn xu efttpo xqp ehkzae wzn woouve ut ufxowapufe tuoxfzp uo xu xwlp wobe wawkzex w epw ut xoufrhpe\"\n```\n:::\n:::\n\n\ndoes not look like English. For example, most words don't have any vowels!\n\nA rough heuristic to see how similar a text is to English is to compute the two letter frequencies and see how similar they are to those in English. Here's an example. `hello there` has the following 2-letter combinations: `\"he\" \"el\" \"ll\" \"lo\" \"o \" \" t\" \"th\" \"he\" \"er\" \"re\"`. You can picture this as a sliding window of width 2.\n\nWe could then compare how close the frequencies in this text align with the frequencies in English. Let $\\text{freq}(x)$ be the frequency of two-letter combination $x$ in English (we'll see how to compute this soon). Then the \"English-similarity\" score for `hello there` could be computed as\n$$\n\\text{freq}(\\text{he}) \\times \\text{freq}(\\text{el}) \\times \\text{freq}(\\text{ll}) \\times \\ldots \\times \\text{freq}(\\text{re})\n$$\n\n### Estimating frequencies based on a sample text\n\nNow let's return to how we implement the $\\text{freq}(x)$ function. An approximation to the true two-letter frequencies could be to find a very long English text and use the frequencies in it by assuming that it is representative of the English language. The text we'll use to do this is *War and Peace* by Leo Tolstoy, a very long book by most standards. Luckily for us, *War and Peace* is in the public domain, and we can download a text file of the book from <https://www.gutenberg.org/>.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwar_and_peace <- readr::read_file(\"https://www.gutenberg.org/cache/epub/2600/pg2600.txt\")\n```\n:::\n\n\nWe'll process the text a bit by:\n\n- Converting all letters to lowercase\n- Removing all non-alphabetical characters (numbers, symbols, etc...) but keep spaces\n- Removing all accent characters (like Ã©)\n\nso that in the end, the text only contains the 26 lowercase letters and the space character.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwar_and_peace <-\n  war_and_peace |>\n  stringr::str_to_lower() |>\n  gsub(pattern = \"[^A-Za-z ]+\", replacement = \"\", x=_) |>\n  stringi::stri_trans_general(id = \"Latin-ASCII\")\n```\n:::\n\n\n### Obtaining two-character frequencies\n\nNow let's design a function to break the text into two-character chunks. We can use the very fast `stringi::stri_sub()` function which, given a starting and ending index, extracts the substrings in between. Since our window has length two, we'll offset the starting and ending indices by one.\n\nWe can test this approach on a short phrase to make sure it works.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_string <- \"hello there\"\n\nstarting_indices <- 1 : (nchar(test_string) - 1)\nending_indices <- starting_indices + 1\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstarting_indices\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  1  2  3  4  5  6  7  8  9 10\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nending_indices\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  2  3  4  5  6  7  8  9 10 11\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstringi::stri_sub(test_string,\n                  from = starting_indices,\n                  to = ending_indices)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"he\" \"el\" \"ll\" \"lo\" \"o \" \" t\" \"th\" \"he\" \"er\" \"re\"\n```\n:::\n:::\n\n\nNow that we see our code works, let's put it into a function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbreak_into_two_chars <- function(text){\n  starting_indices <- 1 : (nchar(text) - 1)\n  ending_indices <- starting_indices + 1\n  return(stringi::stri_sub(text,\n                           from = starting_indices,\n                           to = ending_indices))\n}\n```\n:::\n\n\nWe can now break *War and Peace* into two-character chunks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwar_and_peace_2_characters <- break_into_two_chars(war_and_peace)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(war_and_peace_2_characters)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"th\" \"he\" \"e \" \" p\" \"pr\" \"ro\"\n```\n:::\n:::\n\n\n### Estimated frequencies from *War and Peace*\n\nWe can calculate the empirical probability of any two-letter combination by dividing the number of times it occurs by the total number of two-character chunks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ten most common two-character combinations\nprobability_table <-\n  table(war_and_peace_2_characters) / length(war_and_peace_2_characters)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprobability_table |> head(40)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nwar_and_peace_2_characters\n                        a            b            c            d            e \n9.053610e-04 2.097140e-02 7.463716e-03 6.200291e-03 5.077064e-03 3.436817e-03 \n           f            g            h            i            j            k \n6.412562e-03 2.929341e-03 1.512555e-02 9.208617e-03 4.893754e-04 1.194642e-03 \n           l            m            n            o            p            q \n3.989051e-03 5.850455e-03 4.422150e-03 1.038582e-02 5.434799e-03 4.205930e-04 \n           r            s            t            u            v            w \n4.484022e-03 1.219292e-02 2.646478e-02 1.689283e-03 1.191351e-03 1.207313e-02 \n           x            y            z           a            aa           ab \n1.474379e-04 1.931503e-03 4.179602e-05 4.516603e-03 2.369538e-05 1.161074e-03 \n          ac           ad           ae           af           ag           ah \n2.347817e-03 3.736959e-03 2.501179e-05 5.660563e-04 1.129809e-03 1.260463e-04 \n          ai           aj           ak           al \n2.882938e-03 5.759294e-05 8.388823e-04 4.695634e-03 \n```\n:::\n:::\n\n\nNote that two-letter combinations that look like a single letter are actually a letter and a space, since we are including spaces in our frequencies to help the algorithm learn word boundaries.\n\nHere are the 20 most common combinations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprobability_table |>\n  sort(decreasing = TRUE) |>\n  head(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nwar_and_peace_2_characters\n         e            t          he          th          d            a \n0.033159052 0.026464778 0.024673473 0.024416444 0.022819309 0.020971399 \n         s           t           in           h          an          er \n0.018675251 0.017588225 0.015909144 0.015125551 0.014968898 0.014645720 \n         n            s           w          re          nd           o \n0.012217272 0.012192919 0.012073125 0.011726251 0.011409326 0.010385817 \n         ed          r  \n0.009573263 0.009366257 \n```\n:::\n:::\n\n\nWe can also see the probability of any combination we choose:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the probability of \"ou\"\nprobability_table[\"ou\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         ou \n0.007754971 \n```\n:::\n:::\n\n\nHowever, there are some two-character combinations that do not occur in *War and Peace*. Instead of estimating the probability of these combinations to be zero, we instead approximate the probability by assuming each of them occurred once in the book. To implement this approximation, we use the below function, which returns the empirical probability of any two-character combination.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_prob_two_char <- function(two_char){\n  prob_from_table <- probability_table[two_char]\n  \n  if (is.na(prob_from_table)) {\n    return(1 / length(war_and_peace_2_characters))\n  } else{\n    return(prob_from_table)\n  }\n}\n```\n:::\n\n\nWe can try our function for a combination in *War and Peace* and a combination that is not:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Try a combination in War and Peace\nget_prob_two_char(\"ou\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         ou \n0.007754971 \n```\n:::\n\n```{.r .cell-code}\nprobability_table[\"ou\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         ou \n0.007754971 \n```\n:::\n\n```{.r .cell-code}\n# Try a combination not in War and Peace\nget_prob_two_char(\"qq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3.291025e-07\n```\n:::\n\n```{.r .cell-code}\nprobability_table[\"qq\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<NA> \n  NA \n```\n:::\n:::\n\n\n### Getting the probability of a new text\n\nNow that we have a way to estimate the probability of any two character combination in English, we can use it to score how similar a given text is to English. A first approach, as described above, might be to break the new text into two character chunks, compute the probability of each, and multiply them together.\n\n[`map_dbl()` is a function from the `purrr` package that iterates over each element of an input vector or list, and applies a function to each element. The `_dbl` in the function name means that the expected output is numeric. We need to use `map_dbl()` because our `get_prob_two_char()` function isn't vectorized.]{.aside}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_text <- \"this is a text\"\nsample_text_two_char <- break_into_two_chars(sample_text)\n\nscore <- \n  purrr::map_dbl(sample_text_two_char, get_prob_two_char) |>\n  prod()\n\nscore\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8.63621e-29\n```\n:::\n:::\n\n\nHowever, we see that the score is an extremely small number, about $10^{-55}$. Therefore, for better numerical precision, we should work on the log scale, and then transform back when we need probabilities. Remember, on the log scale we express products as sums. Below is a function to implement this approach:\n\n1) Break the text into two character chunks\n2) Compute the probability of each chunk using our representative English text (*War and Peace*)\n3) Take the log of each probability\n4) Sum the probabilities to get a log-likelihood for the text\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_log_lik_text <- function(text){\n  text |>\n  break_into_two_chars() |>\n  purrr::map_dbl(get_prob_two_char) |>\n  log() |>\n  sum()\n}\n```\n:::\n\n\nLet's see if our score can differentiate English and non-English: a comparison of English words with me hitting random keys.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_log_lik_text(\"This is English text\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -130.5349\n```\n:::\n\n```{.r .cell-code}\nget_log_lik_text(\"fghr gh wghdfrf etfs\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -139.0768\n```\n:::\n:::\n\n\nAs expected the log-likelihood for the English text is higher than for the non-English text.\n\n## Implementing the Metropolis Algorithm\n\nNow we are finally ready to implement our code-breaking algorithm! One helper function we need is a function to swap two elements of a vector. As discussed above, we'll use this to propose a new cipher given the current cipher.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nswap <- function(x){\n  # Select two distinct indices\n  rand_indices <- sample(1:length(x), size = 2, replace=FALSE)\n  element_1 <- x[rand_indices[1]]\n  element_2 <- x[rand_indices[2]]\n  \n  x[rand_indices[1]] <- element_2\n  x[rand_indices[2]] <- element_1\n  \n  return(x)\n}\n```\n:::\n\n\nBelow is the full algorithm, the same one I ran to create the video at the beginning of this post. The steps correspond to the description I gave above, now substituting the functions we have created. Try running it for yourself. A few tips:\n\n- The algorithm may take many iterations to converge, sometimes close to 20,000, although this is highly dependent on the cipher chosen and the starting cipher.\n- Since this is a relatively short text, it may take more iterations to decode. Long texts contain more information, and so are more easily decoded.\n- If the chain doesn't seem to be converging, try a new random seed. I had to try a few random seeds for the algorithm to converge in a reasonable number of iterations^[While this strategy of restarting misbehaving Markov chains isn't a good strategy for other applications of MCMC like Bayesian statistics, it's perfectly reasonable for the optimization task we are performing here.].\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaintext <- \"to be or not to be that is the question whether tis nobler in the mind to suffer the slings and arrows of outrageous fortune or to take arms against a sea of troubles\"\n\n# Generate a random cipher to be the true cipher\ntrue_cipher <- generate_cipher()\n\n# Encode the plaintext\nciphered_text <- encode_text(text = plaintext,\n                             cipher = true_cipher)\n\n# Create another random cipher to be the starting cipher for the Markov Chain\ncurrent_cipher <- generate_cipher()\n\n# A counter to track how many decoded texts have been accepted\ni <- 0\n\nfor (iter in 1:50000) {\n  \n  # Propose a new cipher by swapping two letters in the current cipher\n  proposed_cipher <- swap(current_cipher)\n  \n  # Text decoded from the proposal cipher\n  decoded_text_proposed <- decode_text(ciphered_text,\n                              cipher = proposed_cipher)\n  \n  # Text decoded from the current cipher\n  decoded_text_current <- decode_text(ciphered_text,\n                              cipher = current_cipher)\n  \n  # Log-likelihood of the decoded text from the proposal cipher\n  proposed_log_lik <- get_log_lik_text(decoded_text_proposed)\n  \n  # Log-likelihood of the decoded text from the current cipher\n  current_log_lik <- get_log_lik_text(decoded_text_current)\n  \n  # Acceptance probability of the proposal, defined by the Metropolis algorithm\n  # Remember that subtraction on the log-scale is division on the probability\n  # scale. We exponentiate to get back to the probability scale.\n  acceptance_probability <- min(1, exp(proposed_log_lik - current_log_lik))\n  \n  # Accept or not with probability given by `acceptance_probability`\n  accept <- sample(c(TRUE, FALSE),\n                   size=1,\n                   prob = c(acceptance_probability,\n                            1-acceptance_probability))\n  \n  # IF we accept the proposal, set the proposal cipher as the current cipher\n  # ELSE, go on to the next iteration\n  if (accept) {\n    current_cipher <- proposed_cipher\n    \n    # Print the text as decoded by the current cipher\n    print(glue::glue(\"Iteration {i}: {decoded_text_proposed}\"))\n    \n    # Increment the counter so that we can keep track of acceptances\n    # This is just for printing the output\n    i <- i + 1\n  }\n}\n```\n:::\n\n\nFor clarity, here's the same code without comments.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplaintext <- \"to be or not to be that is the question whether tis nobler in the mind to suffer the slings and arrows of outrageous fortune or to take arms against a sea of troubles\"\n\ntrue_cipher <- generate_cipher()\nciphered_text <- encode_text(text = plaintext,\n                             cipher = true_cipher)\n\ncurrent_cipher <- generate_cipher()\n\ni <- 0\n\nfor (iter in 1:50000) {\n  \n  proposed_cipher <- swap(current_cipher)\n  \n  decoded_text_proposed <- decode_text(ciphered_text,\n                              cipher = proposed_cipher)\n  decoded_text_current <- decode_text(ciphered_text,\n                              cipher = current_cipher)\n  \n  proposed_log_lik <- get_log_lik_text(decoded_text_proposed)\n  current_log_lik <- get_log_lik_text(decoded_text_current)\n  \n  acceptance_probability <- min(1, exp(proposed_log_lik - current_log_lik))\n  \n  accept <- sample(c(TRUE, FALSE),\n                   size=1,\n                   prob = c(acceptance_probability,\n                            1-acceptance_probability))\n  \n  if (accept) {\n    current_cipher <- proposed_cipher\n    print(glue::glue(\"Iteration {i}: {decoded_text_proposed}\"))\n    i <- i + 1\n  }\n}\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}