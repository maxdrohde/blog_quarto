{
  "hash": "0cafefb668d5f6052c38679fb5c221ad",
  "result": {
    "markdown": "---\ntitle: Sensitivity of odds-ratios calculated on dichotomized variables to inclusion criteria\ndescription:  A short simulation example showing why dichomization of continuous variables can lead to wrong conclusions.\nauthor: Max Rohde\ndate: 01/16/2022\nimage: preview.png\ncode-fold: show\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nset.seed(123)\n```\n:::\n\n\n## Motivation\nIn this document, we will show how calculating an odds ratio based on a dichotomized continuous predictor variable can be manipulated by changing the range of the predictor variable that was sampled (i.e, study inclusion criteria), whereas a logistic regression model that uses the continuous values of the predictor will produce a stable estimate.\n\n## Scenario\nAssume that we are interested in a disease where the incidence varies with age.\n\nWe will assume as the true model a simple relationship where the probability of developing the disease is a linear function of age. The below plot shows this relationship.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# True model of disease probability is a linear function of age\np_disease <- function(age){\n  0.25 + 0.0075*age\n}\n\n# Plot true model\ntibble(age = seq(20, 80, length.out=2), prob = p_disease(age)) %>%\n  ggplot() +\n  aes(x=age, y=prob) +\n  geom_line() +\n  labs(title = \"True probability of having the disease\",\n       x=\"Age\",\n       y=\"P(Disease)\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=768}\n:::\n:::\n\n\nWe decide to sample subjects from the population and record if they have the disease. For simplicity, assume we sample patients uniformly within a given age range. We will show that dichotomizing age at a cutpoint is not a good idea, and can lead to estimates that can be greatly affected by the chosen age range to be sampled.\n\nTo dichotomize the predictor variable, let's compare the incidence of disease among old (age > 50) and young (age < 50) patients and calculate an odds ratio, instead of using age as a continuous variable. The below simulation shows the results of two scenarios. As a comparison, we also fit a logistic regression using continuous age.\n\nFirst, we sample 10,000 subjects with ages between 40 and 60. Second, we sample 10,000 subjects with ages between 20 and 80. We show that the choices of inclusion criteria has a large effect on the odds ratio comparing odds of disease between young and old subjects, but the estimates provided by logistic regression are unchanged.\n\n## Simulation\n\n### Sample from ages 40 to 60\n\n::: {.cell}\n\n```{.r .cell-code}\n# Draw 10,000 patients uniformly between 40 and 60\nages <- runif(10000, min=40, max=60)\n\n# Calculate true probabilities for each patient\nprobs <- p_disease(ages)\n\n# Generate data where each patient has `probs` probability of having the disease\ndata <- map_dbl(probs, ~sample(c(0,1), size=1, prob=c(1-.x, .x)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Put simulation data into a data frame\ndf <- tibble(age=ages, prob=probs, disease=data)\n\n# Dichotomize at age = 50\ndf$old <- (df$age > 50)\n\nhead(df)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|      age|      prob| disease|old   |\n|--------:|---------:|-------:|:-----|\n| 45.75155| 0.5931366|       1|FALSE |\n| 55.76610| 0.6682458|       1|TRUE  |\n| 48.17954| 0.6113465|       0|FALSE |\n| 57.66035| 0.6824526|       1|TRUE  |\n| 58.80935| 0.6910701|       1|TRUE  |\n| 40.91113| 0.5568335|       1|FALSE |\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(df$disease, df$old)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n    FALSE TRUE\n  0  2081 1614\n  1  2976 3329\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nodds_ratio <- (3329 / 1614) / (2976 / 2081)\n\nodds_ratio\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.442279\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit logistic regression model using continuous age\nglm(disease ~ age, family=binomial(), data=df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:  glm(formula = disease ~ age, family = binomial(), data = df)\n\nCoefficients:\n(Intercept)          age  \n   -1.23211      0.03547  \n\nDegrees of Freedom: 9999 Total (i.e. Null);  9998 Residual\nNull Deviance:\t    13170 \nResidual Deviance: 13080 \tAIC: 13080\n```\n:::\n:::\n\n\n\n### Sample from ages 20 to 80\n\n::: {.cell}\n\n```{.r .cell-code}\nages <- runif(10000, min=20, max=80)\nprobs <- p_disease(ages)\ndata <- map_dbl(probs, ~sample(c(0,1), size=1, prob=c(1-.x, .x)))\ndf <- tibble(age=ages, prob=probs, disease=data)\ndf$old <- (df$age > 50)\n\ntable(df$disease, df$old)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n    FALSE TRUE\n  0  2400 1179\n  1  2625 3796\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nodds_ratio <- (3796 / 1179) / (2625 / 2400)\n\nodds_ratio\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.943705\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(disease ~ age, family=binomial(), data=df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:  glm(formula = disease ~ age, family = binomial(), data = df)\n\nCoefficients:\n(Intercept)          age  \n   -1.15573      0.03586  \n\nDegrees of Freedom: 9999 Total (i.e. Null);  9998 Residual\nNull Deviance:\t    13040 \nResidual Deviance: 12220 \tAIC: 12230\n```\n:::\n:::\n\n\n## Conclusion\nWe see that when sampling from ages 40 to 60, the dichotomization approach estimated an odds ratio of 1.44 compared to an odds ratio of 2.94 when sampling from ages 20 to 80.\n\nIn contrast, when sampling from ages 40 to 60, the logistic regression estimated a regression coefficient for age of 0.0355 compared to a very similar value of 0.0359 when sampling from ages 20 to 80.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}