{
  "hash": "51032c6453c75fe0605f9a2620508cb0",
  "result": {
    "markdown": "---\ntitle: What is Gradient Descent? (Part I)\ndescription: Exploring gradient descent using R and a minimal amount of mathematics\nauthor: Max Rohde\ndate: 01/16/2021\nimage: preview.png\ncode-fold: show\nfreeze: true\ncache: false\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(gganimate)\n```\n:::\n\n\n## Introduction\n\nGradient descent is an optimization algorithm that finds the minimum of a function. Commonly, the function to be minimized is a loss function: a function that quantifies the \"badness\" associated with the given inputs, which you would naturally want to minimize. A common loss function is the mean-squared error. For example, using mean-squared error, the loss incurred by an inaccurate prediction is the squared distance from the prediction to the true value. Neural networks are commonly optimized using some form of gradient descent.\n\nLet's start with a simple example, where we already know the answer. We wish to minimize the quadratic function given by\n\n\n$$\nf(x) = (x + 2)^2 + 3\n$$\n\n\nThe shape of the function, a parabola, is shown in the plot below. Most applications of gradient descent occur in dimensions much higher than 2D, where we cannot so easily visualize the function we are trying to minimize.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- seq(-10,5,length.out=1e4)\ny <- (x + 2)^2 + 3\n\nplot_data <- tibble(x, y)\n\nplot_data %>%\n  ggplot() +\n  aes(x=x, y=y) +\n  geom_line() +\n  geom_hline(yintercept = 3, linetype=2) +\n  geom_vline(xintercept = -2, linetype=2) +\n  scale_x_continuous(breaks=c(-2)) +\n  scale_y_continuous(breaks=c(3)) +\n  cowplot::theme_cowplot(font_family = \"Lato\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=768}\n:::\n:::\n\n\n\nFinding the minimum is a solved problem using calculus. We can take the first-derivative, set it equal to zero, and solve, to obtain a minimum of $y=3$, which occurs at $x=-2$. Then an application of the second-derivative test confirms that it is minimum, rather than a maximum. Our goal is to reproduce this result using gradient descent.\n\n## An analogy for gradient descent\n\nGradient descent works by starting at a location in the space. Then, each iteration of the algorithm it moves downhill with respect to the function, which is by definition opposite the gradient. The algorithm proceeds downhill until it reaches a minimum where the gradient is zero within some tolerance (success) or the maximum number of iterations is reached (failure). Apart from the tuning parameters of the algorithm, which we will discuss later, the only information gradient descent needs to work is the function to be minimized and its first derivative.\n\nHere's an analogy. Think of a ball moving under the influence of gravity in a landscape of hills and valleys. If you let the ball move freely, it will roll to a point of minimum height in the landscape. Does the ball know the whole landscape and decide to move to the minimum point? No. The only information it uses to find the minimum is the slope at the point it is currently at. The local information is enough. Gravity is constantly moving the ball downhill, based on the slope of the landscape at the current location. \n\n## The gradient descent algorithm\n\nThe general algorithm for gradient descent is as follows:\n\n1. Pick a starting point and a learning rate\n2. Using the derivative of the function, compute the gradient (i.e., slope) at the current point.\n3. Compute the step size: $\\text{delta} = - \\text{gradient} * \\text{learning\\_rate}$\n4. Set $x \\rightarrow x + \\text{delta}$\n5. Repeat from step 2 until either delta is below a certain threshold or a maximum number of iterations is reached\n\nNow, let's go through this step-by-step for our quadratic function example.\n\n1. Pick an arbitrarily chosen starting point of $x=5$. Thus $f(x) = (5 + 2)^2 + 3 = 52$. We also pick a commonly used learning rate of 0.1.\n2. The derivative of $f(x)$ is $\\frac{df}{dx} =  2x+4$. So the gradient is $2(5) + 4 = \\boxed{14}$\n3. Set the step size: $\\text{delta} = - \\text{gradient} * \\text{learning\\_rate} = - 14* 0.01 = \\boxed{-0.14}$\n4. Set the current value of $x$ to $x + delta = 5 - 0.14 = \\boxed{4.86}$\n5. Assume we set the step size (delta) threshold to 0.001 and the maximum number of iteration to 5000. Since neither of these criteria are currently met, we go back to step 2, but now with $x=4.86$, and repeat until we meet one of the exit conditions.\n\n## Implementation in R\n\nNow that we understand the gradient descent algorithm in theory, let's translate this into R code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define f(x) and df/dx\nf <- function(x){(x+2)^2 + 3}\ndf_dx <- function(x){2*x+4}\n\n# Set learning rate\nlearning_rate <- 0.1\n\n# Set starting point\nx <- 5\n\n# Create a counter to track the iteration\niter <- 1\n\nwhile(TRUE){ # Loop until we reach exit conditions\n  \n  # Compute the gradient at the current x value\n  current_grad <- df_dx(x)\n  \n  # Compute delta at the current x value\n  delta <- -current_grad*learning_rate\n  \n  # Compute the updated x value, given delta\n  x <- x + delta\n  \n  # Print the current state of the algorithm\n  # the glue package is used for printing variables easily\n  print(glue(\"Iteration: {iter}\"))\n  print(glue(\"x: {x}\"))\n  print(glue(\"y: {f(x)}\"))\n  print(glue(\"delta: {delta}\"))\n  \n  # Increment the iteration counter\n  iter <- iter + 1\n  \n  # Exit if delta is below the threshold or max iterations have been reached\n  if (abs(delta)<0.001 | iter>5000) {\n    break\n  }\n}\n```\n:::\n\n\nHere's the output from the beginning and end of the algorithm.\n\n```\nIteration: 1\nx: 3.6\ny: 34.36\ndelta: -1.4\nIteration: 2\nx: 2.48\ny: 23.0704\ndelta: -1.12\nIteration: 3\nx: 1.584\ny: 15.845056\ndelta: -0.896\n\n...\n\nIteration: 32\nx: -1.994454028624\ny: 3.0000307577985\ndelta: -0.00138649284399963\nIteration: 33\nx: -1.9955632228992\ny: 3.00001968499104\ndelta: -0.00110919427519969\nIteration: 34\nx: -1.99645057831936\ny: 3.00001259839427\ndelta: -0.000887355420159741\n\n```\n\nWe see that our gradient descent algorithm converged to the minimum at $(3,-2)$, with some error that could be reduced if we lowered the step size threshold.\n\n## Animations\n\nAnimations are a good way to get intuition on how optimization algorithms like gradient descent work. The animation below shows our algorithm using three different learning rates. The code to create the animations can be found [here](https://gist.github.com/maxdrohde/f807b2fbeb7b66532ec8a5e7f3c6e2bf).\n\n::: {.column-page}\n![](gd_anim.mp4){}\n:::\n\n\nUsing a learning rate of 0.01 takes much longer to converge, but with more complicated functions it is less likely to overshoot and miss the minimum. Using a learning rate of 0.95, the algorithm constantly overshoots the minimum and oscillates on either side of it until it finally settles down. A learning rate of 0.1 seems like the best compromise between accuracy and speed, since we know the true minimum.\n\n::: {.column-margin}\n![](lr1.mp4){}\n\nSpecial case is when the learning rate is exactly 1: the algorithm will move between two points on opposite sides on the parabola and remain stuck there\n:::\n\nIn this specific example, a learning rate higher than 1 will constantly overshoot the minimum and will never converge. A special case is when the learning rate is exactly 1: the algorithm will move between two points on opposite sides on the parabola and remain stuck there. See the animation below.\n\nIn real applications, where the true minimum is unknown, trial and error is necessary to find a good learning rate. There are more [complex algorithms](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Extensions_and_variants) that build on gradient descent to automatically tune the learning rate as the algorithm progresses.\n\n## Next steps\n\nIn the next post in this series, we will extend our gradient descent algorithm to optimize over more complex functions: fitting a least-squares regression line, and a logistic regression curve.\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}